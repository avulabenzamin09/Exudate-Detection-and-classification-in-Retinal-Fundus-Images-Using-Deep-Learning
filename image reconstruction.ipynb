{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from resizeimage import resizeimage\n",
    "from PIL import Image\n",
    "from tensorflow.python.ops.image_ops_impl import ResizeMethod  \n",
    "#from pandas_ml import ConfusionMatrix\n",
    "from random import shuffle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape,na):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial,name=na)\n",
    "\n",
    "def bias_variable(shape,na):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=na)\n",
    "\n",
    "def conv2d(xe, W):\n",
    "    return tf.nn.conv2d(xe, W, strides=[ 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def max_pool(xe):\n",
    "    return tf.nn.max_pool(xe, ksize=[1, 3, 3, 1],strides=[1,2,2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_s2(xe):\n",
    "    return tf.nn.max_pool(xe, ksize=[1, 3,3, 1],strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn(is_training,inputs,decay=0.999):\n",
    "    scale=tf.Variable(tf.ones(inputs.get_shape()[-1:]))\n",
    "    beta = tf.Variable(tf.zeros(inputs.get_shape()[-1:]))\n",
    "    pop_mean = tf.Variable(tf.zeros(inputs.get_shape()[-1:]), trainable=False)\n",
    "    pop_var = tf.Variable(tf.ones(inputs.get_shape()[-1:]), trainable=False)\n",
    "    mean = tf.cond(is_training,lambda:tf.nn.moments(inputs,[0,1,2])[0],lambda:tf.ones(tf.shape(inputs.get_shape()[-1:]))*pop_mean)\n",
    "    var = tf.cond(is_training,lambda:tf.nn.moments(inputs,[0,1,2])[1],lambda:tf.ones(tf.shape(inputs.get_shape()[-1:]))*pop_var)\n",
    "    train_mean = tf.cond(is_training,lambda:tf.assign(pop_mean,pop_mean * decay + mean * (1 - decay)),lambda:tf.ones([0]))\n",
    "    train_var= tf.cond(is_training,lambda:tf.assign(pop_var,pop_var * decay + var * (1 - decay)),lambda:tf.ones([0]))\n",
    "    with tf.control_dependencies([train_mean,train_var]):\n",
    "        return tf.nn.batch_normalization(inputs,mean,var,beta,scale,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "xin = tf.placeholder(tf.float32,shape=[None, 30,30,3])\n",
    "y_ = tf.placeholder(tf.float32,shape=[None, 2])\n",
    "epsilon=0.000001\n",
    "is_training=tf.placeholder(tf.bool,[])\n",
    "\n",
    "x_image = tf.reshape(xin, [-1, 30,30, 3])\n",
    "\n",
    "W1=weight_variable([2,2,3,32],'w1')\n",
    "b1=bias_variable([32],'b2')\n",
    "\n",
    "h_conv1=tf.nn.relu(bn(is_training,conv2d(x_image,W1))+b1)\n",
    "\n",
    "\n",
    "w2=weight_variable([2,2,32,32],'w2')\n",
    "b2=bias_variable([32],'b2')\n",
    "conv1=tf.nn.relu(bn(is_training,conv2d(h_conv1,w2))+b2)\n",
    "conv1=max_pool(conv1)\n",
    "\n",
    "w3=weight_variable([2,2,32,64],'w3')\n",
    "b3=bias_variable([64],'b3')\n",
    "conv2=tf.nn.relu(bn(is_training,conv2d(conv1,w3))+b3)\n",
    "\n",
    "w4=weight_variable([2,2,64,64],'w4')\n",
    "b4=bias_variable([64],'b4')\n",
    "conv3=tf.nn.relu(bn(is_training,conv2d(conv2,w4))+b4)\n",
    "conv3=max_pool(conv3)\n",
    "\n",
    "\n",
    "w5=weight_variable([2,2,64,128],'w5')\n",
    "b5=bias_variable([128],'b5')\n",
    "conv4=tf.nn.relu(bn(is_training,conv2d(conv3,w5))+b5)\n",
    "\n",
    "w6=weight_variable([2,2,128,128],'w6')\n",
    "b6=bias_variable([128],'b6')\n",
    "conv5=tf.nn.relu(bn(is_training,conv2d(conv4,w6))+b6)\n",
    "conv5=max_pool(conv5)\n",
    "\n",
    "w7=weight_variable([2,2,128,256],'w7')\n",
    "b7=bias_variable([256],'b7')\n",
    "conv6=tf.nn.relu(bn(is_training,conv2d(conv5,w7))+b7)\n",
    "\n",
    "w8=weight_variable([2,2,256,256],'w8')\n",
    "b8=bias_variable([256],'b8')\n",
    "conv7=tf.nn.relu(bn(is_training,conv2d(conv6,w8))+b8)\n",
    "#conv6=max_pool(conv6)\n",
    "\n",
    "W_fc1=weight_variable([16*256,1000],'w_fc1')\n",
    "b_fc1=bias_variable([1000],'b_fc1')\n",
    "y1=tf.reshape(conv6,[-1,16*256])\n",
    "y_fc1=tf.nn.relu(tf.matmul(y1,W_fc1)+b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(y_fc1, keep_prob)\n",
    "\n",
    "W_fc2=weight_variable([1000,100],'w_fc2')\n",
    "b_fc2=bias_variable([100],'b_fc2')\n",
    "y_fc2=tf.nn.relu(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)\n",
    "\n",
    "W_fc3=weight_variable([100,2],'w_fc3')\n",
    "b_fc3=bias_variable([3],'b_fc3')\n",
    "y_fc3=tf.nn.relu(tf.matmul(y_fc2,W_fc3)+b_fc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.argmax(y_fc3, 1)\n",
    "lab = tf.argmax(y_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_fc3))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "correct_prediction = tf.cast(tf.equal(tf.argmax(y_fc3, 1), tf.argmax(y_, 1)),tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('training')\n",
    "    a=datetime.datetime.now().time()\n",
    "    print(a)\n",
    "    print('session started')\n",
    "    saver.restore(sess,r'../class_he_bg/model_1000.ckpt')\n",
    "    #in each 'i' the model is trained with 1000 images\n",
    "    \n",
    "    #test_he_se=[14,18,19,25,32,38,46,47,49,54]\n",
    "    test_he=[2,4,5,6,16,27,34,37,43,44]\n",
    "    #aa=test_he_se+test_he\n",
    "    for l11,i11 in enumerate(test_he):\n",
    "        a=datetime.datetime.now().time()\n",
    "        print('start time %s'%a)\n",
    "        gen=np.array([])\n",
    "        image=Image.open(r'../Apparent Retinopathy/IDRiD_%02d.jpg'%i11)\n",
    "        g = np.array(resizeimage.resize_cover(image, [512,512]))\n",
    "        gt_ex= Image.open(r'../EX/IDRiD_%02d_EX.tif'%i11)\n",
    "        #gt_se= Image.open(r'/home/smst/Desktop/benjamin/SE/IDRiD_%02d_SE.tif'%i11)\n",
    "        ex=np.array(resizeimage.resize_cover(gt_ex,[512,512]))\n",
    "        ex=ex[15:497,15:497]\n",
    "        #se=np.array(resizeimage.resize_cover(gt_se,[512,512]))\n",
    "        #se=se[15:497,15:497]\n",
    "        npg=np.array(g,dtype='f')\n",
    "        gen=np.array([])\n",
    "        for i2 in range(15,497):\n",
    "            for j2 in range(15,497):\n",
    "                new=npg[i2-15:i2+15,j2-15:j2+15]\n",
    "                new=np.array([new])\n",
    "                if tii.shape[0]%4==0:\n",
    "                    tii=new\n",
    "                else:\n",
    "                    tii=np.append(tii,new,axis=0)\n",
    "                    if tii.shape[0]%4==0:\n",
    "                        pre=pred.eval(feed_dict={xin:tii,is_training:False,keep_prob: 0.5})\n",
    "                        gen=np.append(gen,pre)\n",
    "        n_i=np.reshape(gen,[482,482])\n",
    "        axx=0\n",
    "        n_gt=np.zeros([482,482])\n",
    "        for h1 in range(482):\n",
    "            for w1 in range(482):\n",
    "                if ex[h1,w1]==1:\n",
    "                    n_gt[h1,w1]=1\n",
    "        for he in range(482):\n",
    "            for br in range(482):\n",
    "                if n_gt[he,br]==n_i[he,br]:\n",
    "                    axx+=1\n",
    "        acc=axx/232324.0\n",
    "        n_gt=n_gt*100\n",
    "        print('accuracy of %02d image is: %f'%(test_he[l11],acc))\n",
    "        result1 = Image.fromarray((n_gt).astype(np.uint8))\n",
    "        result1.save(r'../he_se_reco_im/he_reco_gt_%02d.jpg'%test_he[l11])\n",
    "        print('%02d image gt'%test_he[l11])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
